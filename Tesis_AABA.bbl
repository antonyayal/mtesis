% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{medium}
\BIBentryALTinterwordspacing
B.~Priambodo, ``Cooperative vs. preemptive: a quest to maximize concurrency
  power.'' [Online]. Available:
  \url{https://medium.com/traveloka-engineering/cooperative-vs-preemptive-a-quest-to-maximize-concurrency-power-3b10c5a920fe}
\BIBentrySTDinterwordspacing

\bibitem{ComRTT}
V.~Shinde and S.~C. Biday, ``Comparison of real time task scheduling
  algorithms,'' \emph{International Journal of Computer Applications}, vol.
  158, no.~6, pp. 37--41, enero 2017.

\bibitem{NCUDA}
NVIDIA, \emph{NVIDIA CUDA Compute Unified Device Architecture: Programming
  Guide}, version 2.0~ed., NVIDIA, Julio 2008.

\bibitem{gpgpu}
\BIBentryALTinterwordspacing
------, ``Computaci{\'o}n acelerada: Supera los desaf{\'\i}os m{\'a}s
  importantes del mundo.'' [Online]. Available:
  \url{https://la.nvidia.com/object/what-is-gpu-computing-la.html}
\BIBentrySTDinterwordspacing

\bibitem{ArqTX2}
\BIBentryALTinterwordspacing
------. Nvidia jetson tx2 delivers twice the intelligence to the edge.
  [Online]. Available:
  \url{https://devblogs.nvidia.com/jetson-tx2-delivers-twice-intelligence-edge/}
\BIBentrySTDinterwordspacing

\bibitem{jtx2dk}
\BIBentryALTinterwordspacing
------, ``Jetson tx2 developer kit.'' [Online]. Available:
  \url{https://developer.nvidia.com/embedded/jetson-tx2-developer-kit}
\BIBentrySTDinterwordspacing

\bibitem{IeeeSG}
``Ieee standard glossary of software engineering terminology,'' \emph{IEEE Std
  610.12-1990}, pp. 1--84, Dec 1990.

\bibitem{enSWE}
S.~S{\'A}NCHEZ~ALONSO, M.~{\'A}. SICILIA~URBAN, and D.~RODRIGUEZ~GARCIA,
  \emph{Ingenier{\'\i}a del software - un enfoque desde la gu{\'\i}a
  swebok}.\hskip 1em plus 0.5em minus 0.4em\relax Alfaomega Grupo Editor, S.A.
  de C.V, 2012.

\bibitem{Buta2011}
G.~C. Butazzo, \emph{Hard real-time computing systems: predictable scheduling
  algorithms and applications}.\hskip 1em plus 0.5em minus 0.4em\relax Springer
  Science & Business Media, 2011.

\bibitem{PreeK}
J.~Calhoun and H.~J. and, ``Preemption of a cuda kernel function,'' \emph{13th
  ACIS International Conference on Software Engineering, Artificial
  Intelligence, Networking and Parallel/Distributed Computing}, 2012.

\bibitem{EmbSysDes}
S.~Heath, \emph{Embedded systems design}.\hskip 1em plus 0.5em minus
  0.4em\relax EDN Series For Design Engineers, 2003.

\bibitem{TX2CU}
A.~STANCU, E.~CODRES, and M.~M. Guerrero, \emph{Jetson TX2 and CUDA
  Programming}, second edition~ed., NVIDIA, 2018.

\bibitem{stream}
\BIBentryALTinterwordspacing
S.~Rennich, ``Cuda c/c++ streams and concurrency,'' NVIDIA, 2011. [Online].
  Available:
  \url{https://developer.download.nvidia.com/CUDA/training/StreamsAndConcurrencyWebinar.pdf}
\BIBentrySTDinterwordspacing

\bibitem{WPNV}
NVIDIA, \emph{NVIDIA Tesla P100 The Most Advanced Datacenter Accelerator Ever
  Built Featuring Pascal GP100, the World's Fastest GPU}, NVIDIA Corporation,
  2016.

\bibitem{AnPasc}
\BIBentryALTinterwordspacing
J.~P. HURTADO~V., ``An{\'a}lisis a fondo: Arquitectura gpu nvidia pascal --
  dise{\~n}ada para la velocidad,'' 2016. [Online]. Available:
  \url{https://www.ozeros.com/2016/05/analisis-a-fondo-arquitectura-gpu-nvidia-pascal-disenada-para-la-velocidad/}
\BIBentrySTDinterwordspacing

\bibitem{PasAna}
\BIBentryALTinterwordspacing
R.~Smith, ``The nvidia geforce gtx 1080 & gtx 1070 founders editions review:
  Kicking off the finfet generation.'' [Online]. Available:
  \url{https://www.anandtech.com/show/10325/the-nvidia-geforce-gtx-1080-and-1070-founders-edition-review/9}
\BIBentrySTDinterwordspacing

\bibitem{GpuCpu}
\BIBentryALTinterwordspacing
NVIDIA, ``Nvidia sobre la computaci{\'o}n de gpu y la diferencia entre gpu y
  cpu,'' 2018. [Online]. Available:
  \url{https://la.nvidia.com/object/what-is-gpu-computing-la.html}
\BIBentrySTDinterwordspacing

\bibitem{LimPree}
M.~Bertogna and S.~Baruah, ``Limited preemption edf scheduling of sporadic task
  systems,'' \emph{IEEE Transactions on Industrial Informatics}, vol.~6, no.~4,
  pp. 579--591, 2010.

\bibitem{GPUArt}
C.~Hartmann and U.~Margull, ``Gpuart - an application-based limited preemptive
  gpu real-time scheduler for embedded systems,'' \emph{Journal of Systems
  Architecture}, 2018.

\bibitem{TX2I}
\BIBentryALTinterwordspacing
NVIDIA, ``Nvidia jetson tx2: High performance ai at the edge.'' [Online].
  Available:
  \url{www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-tx2/}
\BIBentrySTDinterwordspacing

\bibitem{Pridriven}
Y.~Kang, W.~Joo, S.~Lee, and D.~Shin, ``Priority-driven spatial resource
  sharing scheduling for embedded graphics processing units,'' \emph{Journal of
  Systems Architecture}, vol.~76, pp. 17--27, mayo 2017.

\bibitem{RTFG}
H.~Lee and M.~A.~A. Faruque, ``Run-time scheduling framework for event-driven
  applications on a gpu-based embedded system,'' \emph{IEEE Transactions on
  Computer-Aided Design of Integrated Circuits and Systems}, vol.~35, no.~12,
  pp. 1956--1967, 2016.

\bibitem{DynSche}
M.~Steinberger, ``On dynamic scheduling for the gpu and its applications in
  computer graphics and beyond,'' \emph{IEEE Computer Graphics and
  Applications}, vol.~38, no.~3, pp. 119--130, 2018.

\bibitem{RGEM}
S.~Kato, K.~Lakshmanan, A.~Kumar, M.~Kelkar, Y.~Ishikawa, and R.~R. Rajkumar,
  ``Rgem: A responsive gpgpu execution model for runtime engines,'' \emph{32nd
  IEEE Real-Time Systems Symposium}, 2011.

\bibitem{IntraNode}
C.~Rea{\~n}o, F.~Silla, D.~S. Nikolopoulos, and B.~Varghese, ``Intra-node
  memory safe gpu co-scheduling,'' \emph{IEEE TRANSACTIONS ON PARALLEL AND
  DISTRIBUTED SYSTEMS}, vol.~29, no.~5, 2018.

\bibitem{GPES}
H.~Zhou, G.~Tong, and C.~Liu, ``Gpes: A preemptive execution system for gpgpu
  computing,'' \emph{21st IEEE Real-Time and Embedded Technology and
  Applications Symposium}, 2015.

\bibitem{EffiSha}
G.~Chen, Y.~Zhao, X.~Shen, and H.~Zhou, ``Effisha: A software framework for
  enabling efficient preemptive scheduling of gpu,'' \emph{AMC}, 2017.

\end{thebibliography}
