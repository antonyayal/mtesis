%%Capítulo 3 trabajo relacionado 
\section{Clasificación de la planificación de tareas}

La clasificación planificación de tareas preemptive esta compuesta de diversos tipos dependiendo de sus técnicas de implementación, cómo se describe en la sección \ref{claspree}. 

Las soluciones basadas en hardware son costosas, ya que debemos desarrollar y construir un dispositivo que auxilie con el cambio de contexto, por ejemplo, en el artículo \cite{18} se utilizan extensiones de hardware a modo de registros que almacenan el contexto y en general las direcciones de memoria que contienen la información necesaria para la restauración de la ejecución de un kernel. En \cite{20} se propone la utilización de extensiones de hardware mediante el intercambio equitativo de recursos entre los núcleos de procesamiento, esto realizando un cambio de contexto aplicando el modo preemptive en el espacio de procesamiento. En lugar de intercambiar el contexto de todo el grid, se pretende intercambiar suficientes TB de un kernel en ejecución para que haya suficientes recursos disponibles para despachar la nueva tarea. Otra solución la observamos en \ciite{8}, en donde se de desarrolló un compilador y que emplea una extensión de hardware para reducir la latencia al implementar el modo preemptive, el compilador inserta puntos preemptive utilizando un análisis del ciclo de vida de los registros. Se utiliza una lógica de compresión descompresión para disminuir el tamaño del contexto de una tarea. Es decir, cuando el valor almacenado en un determinado registro es siempre igual a lo largo de la ejecución de los TB de un kernel, sólo se guardará un valor durante el cambio de contexto.

\section{Tarjetas gráficas}

\begin{enumerate}
\item \textbf{REGM: Un modelo de ejecución GPGPU responsivo para soluciones en tiempo de ejecución
	(\textit{REGM: A Responsive GPGPU Execution Model for Runtime Engines})}
	
	El artículo \cite{RGEM} es el primer trabajo que genera un framework para utilizar tareas en tiempo real en tarjetas gráficas. Se basa en la partición en fragmentos de memoria a procesar, cada fragmento es agregado a una cola de procesamiento para ser ejecutado. Su solución es dividir las transacciones de copiado de memoria en varios fragmentos para insertar puntos preemptive. Esto también garantiza que sólo las tareas de mayor prioridad se ejecuten en el GPU en cualquier momento, y así evitar interferencias de rendimiento causadas por lanzamientos concurrentes.
	
	\vspace{0.3cm}
	
	La primer característica de este framework es que se basa en transacciones de datos preemptive, por lo que los tiempos de bloqueo están limitados al tiempo limitado para copiar cada fragmento de dato. La segunda característica es que permite lanzar los kernels de diferentes tareas una por una basadas en su prioridad, lo que evita que las tareas con alta prioridad sean interferidas por la carga simultánea de trabajo una vez iniciadas. Sin embargo el lanzamiento del kernel puede bloquearse al haber un kernel de menor prioridad lanzado anteriormente, esto debido al probable alto uso de memoria global.
		
	\item \textbf{Preemption de una función CUDA KERNEL
	(\textit{Preemption of a CUDA Kernel Function})}
	
	El artículo \cite{PreeK} presenta una solución basada en quantums, en donde para sacar una tarea en ejecución se verifica si ha terminado su tiempo. La prioridad de cada tarea esta dada por una estructura \textit{FIFO}. La implementación permite que un kernel sea detenido, guarde su estado y sea reemplazado, liberando los recursos de la GPU para que se ejecuten otras tareas, lo que ayuda a aumentar la eficiencia del sistema. 

Se propone un esquema de puntos de control colocando una directiva tipo \textit{pragma} dentro de las funciones kernel que ayudará a almacenar su estado de ejecución en la memoria del CPU en vez de la del GPU.

La transferencia entre el CPU y GPU permite que ahorre memoria en el GPU, pero a la vez se posibilita que la ejecución se reanude casi como si el kernel nunca se hubiera detenido.

\item \textbf{GPES: Un sistema de ejecución para cómputo gpgpu
	(\textit{GPES: A preemptive execution system for gpgpu computing})}
	
	El articulo \cite{GPES} implementa una serie de funciones para realizar particiones de kernel y de datos, esto realizando subkernels y dividiendo las transacciones de datos en fragmentos. 
Específicamente, se presenta una técnica de reescritura binaria para reconfigurar de manera transparente el código de los kernel. Mientras que para los kernel un poco más complejos, se desarrolló una técnica de transformación fuente a fuente que compila el código del kernel transformado en binarios CUDA. La prioridad de las tareas esta dada por colas de ejecución. GPES modifica el API de CUDA utilizando las bibliotecas de openCUDA para reconfigurar el código binario de los kernels, esto lo realiza obteniendo un máximo de blocks que se pueden ejecutar por quantum. Para realizar esto, se ayuda de dos implementaciones.

\begin{enumerate}
\item \textit{Transformación fuente a fuente.}
Para dar soporte al cómputo paralelo, el hardware mantiene indices continuos en un grid (\textit{blockIdx}), por ejemplo, si un grid consta de 256 blocks, tiene indices desde 0 a 255. Entonces, para hacer que un kernel sea interrumpible en subkernels, se utiliza el concepto de \textit{blockRange}, el cual se define como el número de blocks que se ejecutarán en un subkernel, limitado por un \textit{blockIdx} inicial y otro final. Está granularidad de bloques ayuda a la reconfiguración de puntos de interrupción que auxilien a que las tareas de mayor prioridad puedan usar la GPU en modo preemptive.

\item \textit{Partición de la transferencia de datos.}
Aunque la transferencia de datos y el cómputo utilizan diferentes motores, la copia de memoria de una aplicación no puede realizarse simultáneamente que el lanzamiento del kernel de otro proceso ya que pertenecen a diferentes contextos. Y una GPU puede contener un contexto a la vez. Por lo tanto en un entorno multitarea, una operación de copia de memoria muy grande de baja prioridad, puede detener a las tareas de alta prioridad. Para evitarlo, GPES busca dividir una transferencia de memoria non-preemptive en múltiples fragmentos más pequeños para volverla preemptive. En el límite de cada fragmento se inserta un punto preemptive, cada fragmento tendrá un tamaño de 4KB.

\end{enumerate}
	
	
\item \textbf{Effisha: Un framework para permitir una planificación preemptive eficiente en gpu 
	(\textit{Effisha: A software framework for enabling efficient preemptive scheduling of gpu,})}
	
\item \textbf{Planificación conjunta con GPU y aseguramiento de la memoria intra-nodo 
	(\textit{Intra-Node Memory Safe GPU Co-Scheduling})}
	El artículo \cite{IntraNode} propone la creación del framework schedGPU, el cual utiliza el administrador de trabajo Slurm para planificar las tareas. Este framework administra las múltiples solicitudes para acceder a las GPU de forma segura al garantizar que no se produzcan sobrecargas de memoria durante su ejecución. Este acceso es controlado mediante bloqueos de archivos, señales del sistema y exclusión mutua.

SchedGPU utiliza el patrón de diseño cliente-servidor ya que toma cada tarea que busca ser lanzada en el GPU como un cliente que está solicitando memoria a un Servidor centralizado (en el mismo nodo), el cual permite que se ejecute si hay suficiente memoria, o en caso contrario la bloquea hasta que se encuentre memoria necesaria para su funcionamiento. El servidor crea un nuevo hilo para cada cliente y mantiene una visión global de la memoria utilizada por todos los clientes a través de la biblioteca de administración de NVIDIA (\textbf{NVML}), esto para evitar la creación de un nuevo contexto que consuma memoria.

\vspace{0.3cm}

La tarea es modificada únicamente al llamar explícitamente las funciones de la biblioteca del cliente para previamente asignar la memoria requerida al GPU. Aunque esto acarrea una gran desventaja al considerar tareas donde no siempre es posible conocer la memoria requerida total de GPU, esto porque la memoria de la GPU se asigna en tiempo de ejecución. En el caso en que dos o más tareas se ejecuten al mismo tiempo y ambas aumenten gradualmente el uso de la memoria del GPU, se puede llegar a utilizar completamente la memoria disponible, con lo que podrán requerir más tiempo para completar la ejecución o directamente lanzar un error en tiempo de ejecución.
	
	%Al utilizar schedGPU se encontró que el promedio de la aceleración aumenta 10 veces, comparado con no utilizar el framework. Sin embargo, el promedio de utilización de la memoria también incrementó de 5 a 12 veces.
	
\item \textbf{Planificación de recursos espaciales compartidos con prioridad para unidades de gráficos embebidos 
	 (\textit{Priority-driven spatial resource sharing scheduling for embedded graphics processing units})}

El artículo \cite{Pridriven} presenta una técnica para la ejecución en GPUs llamada \textit{"Planificación de recursos compartidos con reserva de presupuesto"} o por sus siglas en inglés \textit{BR-SRS}, la cual limita el número de núcleos de procesamiento de una GPU para una tarea basándose en su prioridad, esto lo realiza modificando las bibliotecas de OpenGL-ES. Así se previene que una tarea que se encuentra en segundo plano retrase a otra que se encuentra en ejecución, también se minimiza la sobrecarga de planificación al invocarse solamente dos veces, en el inicio de la tarea y en su finalización.

\end{enumerate}  

\section{Sistemas embebidos}

\begin{enumerate}
\item \textbf{Framework para planificación en tiempo de ejecución de aplicaciones con manejo de eventos en sistemas embebidos basados en GPU 
	(\textit{Run-Time Scheduling Framework for Event-Driven Applications on a GPU-Based Embedded System})}
	
	Para poder utilizar varias aplicaciones en sistemas en tiempo real complejos es necesario la utilizar técnicas de preemption. Algunos trabajos han utilizado estas técnicas para mejorar el rendimiento de las aplicaciones gráficas en tiempo real, principalmente para la reconstrucción de imágenes en 3D y la detección de rostros.

\vspace{0.3cm}

En el artículo \cite{RTFG} se propone un framework de planificación que parte los kernels del GPU y genera secuencias de lanzamiento en subkernels dinámicamente para entrar el modo preemptive con la implementación de un divisor de carga de trabajo y de un planificador de tareas. Utiliza un divisor de carga de trabajo que divide el núcleo de la GPU en múltiples subkernels durante el tiempo de ejecución para implementar el modo preemptive. Dependiendo del estado actual de sistema y de la prioridad, el divisor de carga de trabajo decide el número y el tamaño de cada subkernel. 

\vspace{0.3cm}

Se cuenta con un generador de ejecución planificada, el cual, dependiendo del estado actual de uso de los recursos del sistema y del plazo límite del la tarea, lanza una secuencia de tareas para maximizar el numero de aplicaciones cercanas al su plazo vencido.	
	
\item \textbf{GpuArt: Un planificador de gpu en tiempo real basado en aplicaciones con preemptive limitado para sistemas embebidos
	(\textit{GpuArt: An application-based limited preemptive gpu real-time scheduler for embedded systems})}
\end{enumerate}  	

%----------------------------------------------------------------------
    %RESUMEN
Este capítulo presenta los trabajos relacionados con el tema de esta tesis, se analizan 
\begin{inparaenum}
	\item Planificación de EDF preemptive limitado de sistemas con tareas esporádicas
	 (\textit{Limited Preemption EDF Scheduling of Sporadic Task Systems});
	 %
	 \item Planificación de recursos espaciales compartidos con prioridad para unidades de gráficos embebidos 
	 (\textit{Priority-driven spatial resource sharing scheduling for embedded graphics processing units});
    	 %
	\item Framework para planificación en tiempo de ejecución de aplicaciones con manejo de eventos en sistemas embebidos basados en GPU 
	(\textit{Run-Time Scheduling Framework for Event-Driven Applications on a GPU-Based Embedded System});
		%
	\item Sobre planificación dinámica para el GPU, sus aplicaciones en computación gráfica y más
	(\textit{On Dynamic Scheduling for the GPU and its Applications in Computer Graphics and Beyond}); y
	%
	\item REGM: Un modelo de ejecución GPGPU responsivo para soluciones en tiempo de ejecución
	(\textit{REGM: A Responsive GPGPU Execution Model for Runtime Engines});
	%
    	\item Planificación conjunta con GPU y aseguramiento de la memoria intra-nodo 
	(\textit{Intra-Node Memory Safe GPU Co-Scheduling});
 \end{inparaenum}
%----------------------------------------------------------------------

\vspace{0.3cm}
Cada sección presenta lo propuesto en el trabajo relacionado, donde se describe el problema, los objetivos y la solución a éste. Brevemente se describe la solución propuesta con los resultados obtenidos y por último se presentan las conclusiones del trabajo.


\section{Resumen}
%%%%%

The earliest deadline first (EDF) scheduling algorithm is a typical representative of the dynamic priority scheduling algorithm. However, once the system is overloaded, the deadline miss rate increases and the scheduling performance deteriorates sharply, which causes a reduction in system resource utilization.

En la práctica, ambas visiones de planificación, tanto preemptive, como non-preemptive, tienen ventajas y desventajas comparadas entre sí, por lo que ninguna es superior a la otra. Pero el patrón encontrado es que es necesario en pensar en un Framework qué brinde ayuda a la ejecución de tareas y que permita guardar el contexto en un tiempo específico. 

Hoy en día, los sistemas embebidos basados en GPU han empezado a considerarse esenciales debido a su alta programabilidad y capacidad de desarrollo con técnicas de alto rendimiento, sumado a su bajo consumo energético. Estos exigen una mayor potencia de cálculo y deben responder a muchos eventos, por lo que se han buscado estrategias, y ahora comparten la memoria entre el CPU y el GPU, lo que resulta en una latencia muy cercana a cero.

Se han propuesto diversos frameworks de última generación para planificación de tareas para aprovechar el rendimiento de los sistemas embebidos basados en GPU y su bajo consumo de energía.

%%%%%

%En este capítulo se presenta el resumen de tres trabajos relacionados con la evaluación de los patrones de seguridad. El primer trabajo presenta una métrica de seguridad denominada SC la cual contabiliza el total de amenazas mitigadas por patrones de seguridad entre el total de amenazas. Una de las mejoras que propone es utilizar la aproximación \textit{Twin peaks} que produce una nueva arquitectura en cada ciclo contemplando los mismos casos de uso pero a mayor detalle.

%\vspace{0.3cm}

%El segundo trabajo presenta una metodología que consiste en medir qué extensión de una arquitectura está protegida con respecto a las amenazas de seguridad más relevantes. La metodología consiste en cuatro partes: 1) mapeo de las amenazas con los objetivos de seguridad, 2) clasificación de las amenazas de acuerdo a su severidad, 3) determinación de la protección ante una amenaza y 4) cálculo de la cobertura de seguridad. 

%\vspace{0.3cm}

%Por último, el tercer trabajo presenta una metodología que permite elegir los patrones de seguridad con respecto a los objetivos de seguridad y las métricas que evaluarán a los patrones. La metodología se divide en tres fases que son: 1) definición de los patrones de seguridad a partir de los objetivos de seguridad, 2) selección de métricas e 3) interpretación de resultados. Este trabajo tiene como objetivo integrar las métricas a la evaluación de un sistema que está utilizando los patrones de seguridad. 